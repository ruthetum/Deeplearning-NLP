{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machineTranslation(characterLevel).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPh8GmWGKwHQslpzufJXaxX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruthetum/Deeplearning-NLP/blob/master/machineTranslation(characterLevel).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVwxC4wUvlEx",
        "colab_type": "text"
      },
      "source": [
        "# Character-Level Neural Machine Translation 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJlbCkHNt7Ay",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b79bcbbe-cddd-4262-db5b-e032d4280098"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "print('version : ', tf.__version__)\n",
        "print('GPU Available : ', tf.test.is_gpu_available())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "version :  2.2.0-rc2\n",
            "WARNING:tensorflow:From <ipython-input-1-a840f7824ccb>:6: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n",
            "GPU Available :  True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5c3HPCZv9pP",
        "colab_type": "text"
      },
      "source": [
        "# 1) 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHLz8f5Pvmsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "486332d5-f10f-468c-f5c0-e31f8e3d86aa"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNZ2hJIwvo4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "91be27b8-a5bc-4920-c909-8ff31fd2a35a"
      },
      "source": [
        "import pandas as pd\n",
        "lines = pd.read_csv('gdrive/My Drive/Colab Notebooks/data/fra.txt', sep='\\t')\n",
        "print(len(lines))\n",
        "lines.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "175622\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Go.</th>\n",
              "      <th>Va !</th>\n",
              "      <th>CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) &amp; #1158250 (Wittydev)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Qui ?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Go.  ... CC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)\n",
              "0   Hi.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #5...                             \n",
              "1   Hi.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #5...                             \n",
              "2  Run!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #9...                             \n",
              "3  Run!  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #9...                             \n",
              "4  Who?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...                             \n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RridCAuX0hFX",
        "colab_type": "text"
      },
      "source": [
        "# 2) 정제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOpFvIFXyrma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "38808c5e-297c-4add-b098-3c0dea2e08d6"
      },
      "source": [
        "lines = lines[[\"Go.\", \"Va !\"]]\n",
        "lines.rename(columns={\"Go.\":\"src\", \"Va !\":\"tar\"},inplace=True)\n",
        "lines.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Salut.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Cours !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Courez !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Qui ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    src       tar\n",
              "0   Hi.   Salut !\n",
              "1   Hi.    Salut.\n",
              "2  Run!   Cours !\n",
              "3  Run!  Courez !\n",
              "4  Who?     Qui ?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfJzBoLmx4ov",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "802adb00-f367-4e3a-f48e-b3f20c6ea672"
      },
      "source": [
        "lines = lines[0:60000] # 6만개만 저장\n",
        "lines.sample(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>Cool off!</td>\n",
              "      <td>Détends-toi !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49223</th>\n",
              "      <td>It's going to be close.</td>\n",
              "      <td>Ça va être serré.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45653</th>\n",
              "      <td>You're not very funny.</td>\n",
              "      <td>Tu n'es pas très amusant.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28015</th>\n",
              "      <td>Did you drink a lot?</td>\n",
              "      <td>Est-ce que tu as bu beaucoup ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50293</th>\n",
              "      <td>The reception was warm.</td>\n",
              "      <td>L'accueil était chaleureux.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25657</th>\n",
              "      <td>Stop joking around.</td>\n",
              "      <td>Arrêtez de chahuter !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20960</th>\n",
              "      <td>They kidnapped me.</td>\n",
              "      <td>Elles m'ont enlevée.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25819</th>\n",
              "      <td>The alarm went off.</td>\n",
              "      <td>L'alarme sonna.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16859</th>\n",
              "      <td>We need to leave.</td>\n",
              "      <td>On doit partir.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38290</th>\n",
              "      <td>We got to be friends.</td>\n",
              "      <td>Nous sommes devenus des amis.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           src                             tar\n",
              "250                  Cool off!                   Détends-toi !\n",
              "49223  It's going to be close.               Ça va être serré.\n",
              "45653   You're not very funny.       Tu n'es pas très amusant.\n",
              "28015     Did you drink a lot?  Est-ce que tu as bu beaucoup ?\n",
              "50293  The reception was warm.     L'accueil était chaleureux.\n",
              "25657      Stop joking around.           Arrêtez de chahuter !\n",
              "20960       They kidnapped me.            Elles m'ont enlevée.\n",
              "25819      The alarm went off.                 L'alarme sonna.\n",
              "16859        We need to leave.                 On doit partir.\n",
              "38290    We got to be friends.   Nous sommes devenus des amis."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixZZnssbwQJr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "d5772a31-f2b6-4b91-fa6d-eb9e8150b316"
      },
      "source": [
        "# \\t : <sos> , \\n : <eos> 라고 생각\n",
        "lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n",
        "lines.sample(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>tar</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>56544</th>\n",
              "      <td>Stay a while and listen.</td>\n",
              "      <td>\\t Restez un peu et écoutez ! \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31958</th>\n",
              "      <td>Tom made a sandwich.</td>\n",
              "      <td>\\t Tom prépara un sandwich. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7157</th>\n",
              "      <td>Are you lonely?</td>\n",
              "      <td>\\t Êtes-vous esseulé ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18017</th>\n",
              "      <td>Do you have a dog?</td>\n",
              "      <td>\\t As-tu un chien ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17495</th>\n",
              "      <td>You're all crazy.</td>\n",
              "      <td>\\t Vous êtes toutes folles. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13595</th>\n",
              "      <td>Close the window.</td>\n",
              "      <td>\\t Ferme la fenêtre. \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22684</th>\n",
              "      <td>Can I see that one?</td>\n",
              "      <td>\\t Puis-je voir celui-ci ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45282</th>\n",
              "      <td>Why did they hire you?</td>\n",
              "      <td>\\t Pourquoi vous ont-ils recruté ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13687</th>\n",
              "      <td>Do you feel sick?</td>\n",
              "      <td>\\t Te sens-tu malade ? \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>817</th>\n",
              "      <td>Keep that.</td>\n",
              "      <td>\\t Gardez cela. \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            src                                    tar\n",
              "56544  Stay a while and listen.       \\t Restez un peu et écoutez ! \\n\n",
              "31958      Tom made a sandwich.         \\t Tom prépara un sandwich. \\n\n",
              "7157            Are you lonely?              \\t Êtes-vous esseulé ? \\n\n",
              "18017        Do you have a dog?                 \\t As-tu un chien ? \\n\n",
              "17495         You're all crazy.         \\t Vous êtes toutes folles. \\n\n",
              "13595         Close the window.                \\t Ferme la fenêtre. \\n\n",
              "22684       Can I see that one?          \\t Puis-je voir celui-ci ? \\n\n",
              "45282    Why did they hire you?  \\t Pourquoi vous ont-ils recruté ? \\n\n",
              "13687         Do you feel sick?              \\t Te sens-tu malade ? \\n\n",
              "817                  Keep that.                     \\t Gardez cela. \\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-LCh5Etz8II",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 글자 집합 구축\n",
        "src_vocab=set()\n",
        "\n",
        "# 1줄씩 읽음\n",
        "for line in lines.src:\n",
        "    # 1개의 글자씩 읽음 (프랑스어는 단어가 아니라 글자)\n",
        "    for char in line:\n",
        "        src_vocab.add(char)\n",
        "\n",
        "tar_vocab=set()\n",
        "for line in lines.tar:\n",
        "    for char in line:\n",
        "        tar_vocab.add(char)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCYphx9g0Iqf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "12c761c1-8b68-4705-b529-f7c8161f610f"
      },
      "source": [
        "src_vocab_size = len(src_vocab)+1\n",
        "tar_vocab_size = len(tar_vocab)+1\n",
        "print(src_vocab_size)\n",
        "print(tar_vocab_size)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "79\n",
            "106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwO8cJDq0nmb",
        "colab_type": "text"
      },
      "source": [
        "# 3) 정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbWLPPsp0QsZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ed4b18a6-35c1-4bc1-85ed-d24643d10835"
      },
      "source": [
        "src_vocab = sorted(list(src_vocab))\n",
        "tar_vocab = sorted(list(tar_vocab))\n",
        "print(src_vocab[45:75])\n",
        "print(tar_vocab[45:75])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "['T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJHBCsMD0VUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d198a751-dc38-4d3c-8235-b7f81a0c9f23"
      },
      "source": [
        "src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n",
        "tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n",
        "print(src_to_index)\n",
        "print(tar_to_index)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76, '’': 77, '€': 78}\n",
            "{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, '(': 10, ')': 11, ',': 12, '-': 13, '.': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, '?': 26, 'A': 27, 'B': 28, 'C': 29, 'D': 30, 'E': 31, 'F': 32, 'G': 33, 'H': 34, 'I': 35, 'J': 36, 'K': 37, 'L': 38, 'M': 39, 'N': 40, 'O': 41, 'P': 42, 'Q': 43, 'R': 44, 'S': 45, 'T': 46, 'U': 47, 'V': 48, 'W': 49, 'X': 50, 'Y': 51, 'Z': 52, 'a': 53, 'b': 54, 'c': 55, 'd': 56, 'e': 57, 'f': 58, 'g': 59, 'h': 60, 'i': 61, 'j': 62, 'k': 63, 'l': 64, 'm': 65, 'n': 66, 'o': 67, 'p': 68, 'q': 69, 'r': 70, 's': 71, 't': 72, 'u': 73, 'v': 74, 'w': 75, 'x': 76, 'y': 77, 'z': 78, '\\xa0': 79, '«': 80, '»': 81, 'À': 82, 'Ç': 83, 'É': 84, 'Ê': 85, 'Ô': 86, 'à': 87, 'â': 88, 'ç': 89, 'è': 90, 'é': 91, 'ê': 92, 'ë': 93, 'î': 94, 'ï': 95, 'ô': 96, 'ù': 97, 'û': 98, 'œ': 99, 'С': 100, '\\u2009': 101, '\\u200b': 102, '‘': 103, '’': 104, '\\u202f': 105}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_NsUdgg0-b2",
        "colab_type": "text"
      },
      "source": [
        "**영어 정수 인코딩**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lORGAvD_0bVs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8dd03073-2965-423f-e49d-3aac6e79580c"
      },
      "source": [
        "encoder_input = []\n",
        "\n",
        "#입력 데이터에서 1줄씩 문장을 읽음\n",
        "for line in lines.src: \n",
        "    temp_X = []\n",
        "    #각 줄에서 1개씩 글자를 읽음\n",
        "    for w in line:\n",
        "      # 글자를 해당되는 정수로 변환\n",
        "      temp_X.append(src_to_index[w])\n",
        "    encoder_input.append(temp_X)\n",
        "print(encoder_input[:5])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[31, 58, 10], [31, 58, 10], [41, 70, 63, 2], [41, 70, 63, 2], [46, 57, 64, 23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p527cVIl1GJU",
        "colab_type": "text"
      },
      "source": [
        "**프랑스어 정수 인코딩**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3RW-dtK0wQH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8105cfd0-c7db-40ee-c7c8-c723063c8b51"
      },
      "source": [
        "decoder_input = []\n",
        "\n",
        "for line in lines.tar:\n",
        "    temp_X = []\n",
        "    for w in line:\n",
        "      temp_X.append(tar_to_index[w])\n",
        "    decoder_input.append(temp_X)\n",
        "print(decoder_input[:5])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [1, 3, 45, 53, 64, 73, 72, 14, 3, 2], [1, 3, 29, 67, 73, 70, 71, 105, 4, 3, 2], [1, 3, 29, 67, 73, 70, 57, 78, 105, 4, 3, 2], [1, 3, 43, 73, 61, 3, 26, 3, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E83IXmGS14J2",
        "colab_type": "text"
      },
      "source": [
        "**1 이 사라졌다는 것 -> '\\t'가 사라졌다는 것**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO2e3aLX1Im9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46e3062f-e139-4034-9fb6-23380749c1e3"
      },
      "source": [
        "# 실제 예측값에는 <sos> 여기서는 \\t 가 있을 필요가 없음\n",
        "decoder_target = []\n",
        "\n",
        "for line in lines.tar:\n",
        "    t=0\n",
        "    temp_X = []\n",
        "    for w in line:\n",
        "      if t>0:\n",
        "        temp_X.append(tar_to_index[w])\n",
        "      t=t+1\n",
        "    decoder_target.append(temp_X)\n",
        "print(decoder_target[:5])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3, 45, 53, 64, 73, 72, 3, 4, 3, 2], [3, 45, 53, 64, 73, 72, 14, 3, 2], [3, 29, 67, 73, 70, 71, 105, 4, 3, 2], [3, 29, 67, 73, 70, 57, 78, 105, 4, 3, 2], [3, 43, 73, 61, 3, 26, 3, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXkCasAm1U5n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b5ad0352-d06a-41ee-fc91-03966be6d41d"
      },
      "source": [
        "# 패딩을 위해 길이 확인\n",
        "max_src_len = max([len(line) for line in lines.src])\n",
        "max_tar_len = max([len(line) for line in lines.tar])\n",
        "print(max_src_len)\n",
        "print(max_tar_len)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25\n",
            "76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS6byOr61sOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 영어, 프랑스어 각각 max_len에 맞추어 패딩\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajfxy1vb2PCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 원-핫 벡터\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-xD3tbO62Yq",
        "colab_type": "text"
      },
      "source": [
        "# 4) 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnQHs_6G4jWF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "encoder_inputs = Input(shape=(None, src_vocab_size))\n",
        "encoder_lstm = LSTM(units=256, return_state=True)\n",
        "# encoder_outputs도 같이 리턴받기는 했지만 여기서는 필요없으므로 이 값은 버림.\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "# 은닉 상태, 셀 상태 -> 컨텍스터 \n",
        "encoder_states = [state_h, state_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCIHSjjs5rcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoder_inputs = Input(shape=(None, tar_vocab_size))\n",
        "decoder_lstm = LSTM(units=256, return_sequences=True, return_state=True)\n",
        "# 디코더의 첫 상태를 인코더의 은닉 상태, 셀 상태로\n",
        "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_softmax_layer = Dense(tar_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfyKVhtF5wuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41503e1e-b293-421b-c20e-200e21056b79"
      },
      "source": [
        "model.fit(x=[encoder_input, decoder_input], y=decoder_target, batch_size=64, epochs=50, validation_split=0.2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "750/750 [==============================] - 18s 24ms/step - loss: 0.7755 - val_loss: 0.6928\n",
            "Epoch 2/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.4803 - val_loss: 0.5537\n",
            "Epoch 3/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.4023 - val_loss: 0.4913\n",
            "Epoch 4/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3578 - val_loss: 0.4531\n",
            "Epoch 5/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3283 - val_loss: 0.4299\n",
            "Epoch 6/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.3069 - val_loss: 0.4098\n",
            "Epoch 7/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.2900 - val_loss: 0.3963\n",
            "Epoch 8/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.2765 - val_loss: 0.3875\n",
            "Epoch 9/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.2653 - val_loss: 0.3812\n",
            "Epoch 10/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.2554 - val_loss: 0.3735\n",
            "Epoch 11/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.2470 - val_loss: 0.3697\n",
            "Epoch 12/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.2393 - val_loss: 0.3676\n",
            "Epoch 13/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.2325 - val_loss: 0.3649\n",
            "Epoch 14/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.2262 - val_loss: 0.3633\n",
            "Epoch 15/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.2204 - val_loss: 0.3631\n",
            "Epoch 16/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.2151 - val_loss: 0.3634\n",
            "Epoch 17/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.2100 - val_loss: 0.3622\n",
            "Epoch 18/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.2055 - val_loss: 0.3618\n",
            "Epoch 19/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.2011 - val_loss: 0.3639\n",
            "Epoch 20/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1971 - val_loss: 0.3642\n",
            "Epoch 21/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1932 - val_loss: 0.3638\n",
            "Epoch 22/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1895 - val_loss: 0.3665\n",
            "Epoch 23/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1861 - val_loss: 0.3686\n",
            "Epoch 24/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1829 - val_loss: 0.3702\n",
            "Epoch 25/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1796 - val_loss: 0.3713\n",
            "Epoch 26/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1766 - val_loss: 0.3732\n",
            "Epoch 27/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1739 - val_loss: 0.3766\n",
            "Epoch 28/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1711 - val_loss: 0.3789\n",
            "Epoch 29/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1685 - val_loss: 0.3832\n",
            "Epoch 30/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1658 - val_loss: 0.3854\n",
            "Epoch 31/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1635 - val_loss: 0.3863\n",
            "Epoch 32/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1612 - val_loss: 0.3890\n",
            "Epoch 33/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1590 - val_loss: 0.3915\n",
            "Epoch 34/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1568 - val_loss: 0.3945\n",
            "Epoch 35/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1546 - val_loss: 0.3982\n",
            "Epoch 36/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1528 - val_loss: 0.3994\n",
            "Epoch 37/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1508 - val_loss: 0.4037\n",
            "Epoch 38/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1490 - val_loss: 0.4060\n",
            "Epoch 39/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1471 - val_loss: 0.4085\n",
            "Epoch 40/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1455 - val_loss: 0.4111\n",
            "Epoch 41/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1438 - val_loss: 0.4143\n",
            "Epoch 42/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1424 - val_loss: 0.4167\n",
            "Epoch 43/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1406 - val_loss: 0.4185\n",
            "Epoch 44/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1393 - val_loss: 0.4223\n",
            "Epoch 45/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1377 - val_loss: 0.4241\n",
            "Epoch 46/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1363 - val_loss: 0.4246\n",
            "Epoch 47/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1349 - val_loss: 0.4297\n",
            "Epoch 48/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1336 - val_loss: 0.4289\n",
            "Epoch 49/50\n",
            "750/750 [==============================] - 16s 22ms/step - loss: 0.1323 - val_loss: 0.4348\n",
            "Epoch 50/50\n",
            "750/750 [==============================] - 16s 21ms/step - loss: 0.1310 - val_loss: 0.4371\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb528ab16d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnjNdGR86sAy",
        "colab_type": "text"
      },
      "source": [
        "# 5) seq2seq 기계 번역기 동작\n",
        "\n",
        "1. 번역하고자 하는 입력 문장이 인코더에 들어가서 은닉 상태와 셀 상태를 얻음\n",
        "2. 상태와 'sos'에 해당하는 '\\t'를 디코더로 보냄.\n",
        "3. 디코더가 'eos'에 해당하는 '\\n'이 나올 때까지 다음 문자를 예측하는 행동을 반복"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-oJledM6W8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0mZyAZA6Xsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이전 시점의 상태들을 저장하는 텐서\n",
        "decoder_state_input_h = Input(shape=(256,))\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "\n",
        "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음\n",
        "decoder_states = [state_h, state_c]\n",
        "\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUY3lhGD6gpy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_to_src = dict((i, char) for char, i in src_to_index.items())\n",
        "index_to_tar = dict((i, char) for char, i in tar_to_index.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XocGOWi6iZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # 입력으로부터 인코더의 상태를 얻음\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "    target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "\n",
        "    # stop_condition이 True가 될 때까지 루프 반복\n",
        "    while not stop_condition:\n",
        "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # 예측 결과를 문자로 변환\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = index_to_tar[sampled_token_index]\n",
        "\n",
        "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
        "        if (sampled_char == '\\n' or\n",
        "           len(decoded_sentence) > max_tar_len):\n",
        "            stop_condition = True\n",
        "\n",
        "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "        target_seq = np.zeros((1, 1, tar_vocab_size))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.\n",
        "\n",
        "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqrF9DSl6j8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "outputId": "dfdf8e45-2709-4aef-b37f-49a54714141c"
      },
      "source": [
        "import numpy as np\n",
        "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n",
        "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(35 * \"-\")\n",
        "    print('입력 문장:', lines.src[seq_index])\n",
        "    print('정답 문장:', lines.tar[seq_index][1:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
        "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1]) # '\\n'을 빼고 출력"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "입력 문장: Run!\n",
            "정답 문장:  Courez ! \n",
            "번역기가 번역한 문장:  Cours ! \n",
            "-----------------------------------\n",
            "입력 문장: I lost.\n",
            "정답 문장:  J'ai perdu. \n",
            "번역기가 번역한 문장:  J'ai perdu. \n",
            "-----------------------------------\n",
            "입력 문장: Come in.\n",
            "정답 문장:  Entre ! \n",
            "번역기가 번역한 문장:  Entre. \n",
            "-----------------------------------\n",
            "입력 문장: I did it.\n",
            "정답 문장:  Je l'ai fait. \n",
            "번역기가 번역한 문장:  Je l'ai fait. \n",
            "-----------------------------------\n",
            "입력 문장: We're shy.\n",
            "정답 문장:  Nous sommes timides. \n",
            "번역기가 번역한 문장:  Nous sommes toujours. \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}