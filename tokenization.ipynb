{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tokenization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO6yLg+KnOvMw4fNaQKdzJ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruthetum/Deeplearning-NLP/blob/master/tokenization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8MLKbqMzoiM",
        "colab_type": "text"
      },
      "source": [
        "# 기본 세팅"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qGLhPimzh7c",
        "colab_type": "code",
        "outputId": "10ea7f09-adb0-4ba0-ad36-9a57048e1cb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaAVGrtIyts7",
        "colab_type": "code",
        "outputId": "311276f0-9cde-4ea2-ca7c-b8723ccc866d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmtpj2H_y1jz",
        "colab_type": "text"
      },
      "source": [
        "Don't 와 Jone's 에서\n",
        "\n",
        "Don't 는 Do 와 n't\n",
        "\n",
        "Jone's 는 Jone 과 's 로 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOEUEoq8ywZ-",
        "colab_type": "code",
        "outputId": "1b61e27b-415c-46e3-c87f-f6ad5582bf2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "print(word_tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu4L-G-KzEee",
        "colab_type": "text"
      },
      "source": [
        "WordPunctTokenizer는 구두점을 별로로 분류하는 특징을 갖고 있기 때문에\n",
        "word_tokenize와 다르게 분류"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54SHEo2mzAnu",
        "colab_type": "code",
        "outputId": "0e4b40f9-b4bf-4725-8681-dce2ec12bf18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "print(WordPunctTokenizer().tokenize(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-HTIgWWzJwy",
        "colab_type": "text"
      },
      "source": [
        "Keras 토큰화 도구 : text_to_word_sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSECTGnezQhy",
        "colab_type": "code",
        "outputId": "31a4f8d2-33ab-421e-d6db-7da7c2c88567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "print(text_to_word_sequence(\"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuddRTkZ1iiy",
        "colab_type": "text"
      },
      "source": [
        "Penn Treebacnk Tokenization : 표준으로 쓰이고 있는 토큰화 방법 중 하나\n",
        "\n",
        "규칙 1. 하이푼으로 구성된 단어는 하나로 유지\n",
        "\n",
        "규칙 2. dosen't와 같이 어퍼스트로피로 '접어'가 함께하는 단어는 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W129ubtVzPWs",
        "colab_type": "code",
        "outputId": "6316d076-c49a-492b-e927-360c91ca5a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "tokenizer=TreebankWordTokenizer()\n",
        "text=\"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n",
        "print(tokenizer.tokenize(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUHTPdGE3DNn",
        "colab_type": "text"
      },
      "source": [
        "sent_tokenize : NLTK에서 영어 문장 토큰화 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEM3ftca207J",
        "colab_type": "code",
        "outputId": "9a4b1099-acb9-4ef1-baef-dcd00fa919fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text=\"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to mae sure no one was near.\"\n",
        "print(sent_tokenize(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to mae sure no one was near.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAUZ2x0x3LJy",
        "colab_type": "text"
      },
      "source": [
        "온점이 문장 끝이 아니라 여러 번 등장하는 경우 -> 이것도 잘 해냄. (온점을 단순히 구분자로 설정하지 않았기 때문에)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYEJ0FDv23wk",
        "colab_type": "code",
        "outputId": "605e55be-4b91-4972-c73d-cf69d1a422b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text=\"I am actively looking for Ph.D. students. and you are a Ph.D student.\"\n",
        "print(sent_tokenize(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di70ICvG3xn6",
        "colab_type": "text"
      },
      "source": [
        "한국어에 대한 문장 토큰화 도구 KSS (Korean Sentence Splitter)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG5BZ-2C3yO5",
        "colab_type": "code",
        "outputId": "44ce68cc-195f-4caa-fc71-1330e9c282de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "pip install kss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kss\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/e1/ff733dfcdf26212b4a56fd144a407ee939cbb2f24e71c0bc1abaf808264a/kss-1.2.5.tar.gz\n",
            "Building wheels for collected packages: kss\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-1.2.5-cp36-cp36m-linux_x86_64.whl size=247424 sha256=68d91f214fa539cd15f3dff0e009630921b914a2367d26c701cf4b01d0f49bed\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/9c/07/cbce306cb767e7428e4da5301e55834937ed1984ba564ca993\n",
            "Successfully built kss\n",
            "Installing collected packages: kss\n",
            "Successfully installed kss-1.2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67JCjuf23zt0",
        "colab_type": "code",
        "outputId": "0ff03f55-7eaa-46cc-d71b-f3ae9bb4b0db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import kss\n",
        "text='딥 러닝 자연어 처리가 재미있기는 합니다. 그런데 문제는 영어보다 한국어로 할 때 너무 어려워요. 농담아니에요. 이제 해보면 알걸요?'\n",
        "print(kss.split_sentences(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['딥 러닝 자연어 처리가 재미있기는 합니다.', '그런데 문제는 영어보다 한국어로 할 때 너무 어려워요.', '농담아니에요.', '이제 해보면 알걸요?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emjo6yfX7m6m",
        "colab_type": "text"
      },
      "source": [
        "품사 태깅 (Post of speech tagging) - 영어\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb4pgG6S7gW8",
        "colab_type": "code",
        "outputId": "3e624bde-93d8-48f8-f758-1fc885df5be8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text=\"I am actively looking for Ph.D. students. and you are a Ph.D. student.\"\n",
        "print(word_tokenize(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'am', 'actively', 'looking', 'for', 'Ph.D.', 'students', '.', 'and', 'you', 'are', 'a', 'Ph.D.', 'student', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pilf4-xM7rnu",
        "colab_type": "code",
        "outputId": "0254e5e3-3bf9-44c3-b236-0987b7b52c44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "from nltk.tag import pos_tag\n",
        "x=word_tokenize(text)\n",
        "pos_tag(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('I', 'PRP'),\n",
              " ('am', 'VBP'),\n",
              " ('actively', 'RB'),\n",
              " ('looking', 'VBG'),\n",
              " ('for', 'IN'),\n",
              " ('Ph.D.', 'NNP'),\n",
              " ('students', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('and', 'CC'),\n",
              " ('you', 'PRP'),\n",
              " ('are', 'VBP'),\n",
              " ('a', 'DT'),\n",
              " ('Ph.D.', 'NNP'),\n",
              " ('student', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVBKtWFg8EaG",
        "colab_type": "text"
      },
      "source": [
        "품사 태깅 (Post of speech tagging) - 한국어\n",
        "\n",
        "1.   Okt (구 Twitter)\n",
        "2.   kkma (꼬꼬마)\n",
        "\n",
        "한국어 NLP에서 형태소 분석기 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy-SWe8B8LSR",
        "colab_type": "code",
        "outputId": "3349963b-a4ec-4939-a2af-3ba1374faca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "pip install konlpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
            "Collecting tweepy>=3.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/36/1b/2bd38043d22ade352fc3d3902cf30ce0e2f4bf285be3b304a2782a767aec/tweepy-3.8.0-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.2)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/3c/1dbe5d6943b5c68e8df17c8b3a05db4725eadb5c7b7de437506aa3030701/JPype1-0.7.2-cp36-cp36m-manylinux1_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 66.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.8)\n",
            "Installing collected packages: colorama, tweepy, beautifulsoup4, JPype1, konlpy\n",
            "  Found existing installation: tweepy 3.6.0\n",
            "    Uninstalling tweepy-3.6.0:\n",
            "      Successfully uninstalled tweepy-3.6.0\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-0.7.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rq4vBTMH9BFP",
        "colab_type": "text"
      },
      "source": [
        "1. Okt (구 Twitter) 분석기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irWt4ZBV8a0X",
        "colab_type": "code",
        "outputId": "59593635-4251-494e-9867-f2e8d66e0420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "import konlpy\n",
        "from konlpy.tag import Okt  \n",
        "okt=Okt()  \n",
        "print(okt.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['열심히', '코딩', '한', '당신', ',', '연휴', '에는', '여행', '을', '가봐요']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0xuj5cl8qjH",
        "colab_type": "code",
        "outputId": "ebe6d4f9-b0ea-41c1-ff3a-cb7a58b53267",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "print(okt.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('열심히', 'Adverb'), ('코딩', 'Noun'), ('한', 'Josa'), ('당신', 'Noun'), (',', 'Punctuation'), ('연휴', 'Noun'), ('에는', 'Josa'), ('여행', 'Noun'), ('을', 'Josa'), ('가봐요', 'Verb')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5UKVBo78w59",
        "colab_type": "code",
        "outputId": "c5b9fff2-5a36-4145-c32e-1c4fa78b2047",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(okt.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['코딩', '당신', '연휴', '여행']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZI3DdqY9XVk",
        "colab_type": "text"
      },
      "source": [
        "2. kkma (꼬꼬마) 분석기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYBt0zFK82wF",
        "colab_type": "code",
        "outputId": "b0019be8-5cc8-45fc-8980-181380b2f441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "from konlpy.tag import Kkma  \n",
        "kkma=Kkma()  \n",
        "print(kkma.morphs(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['열심히', '코딩', '하', 'ㄴ', '당신', ',', '연휴', '에', '는', '여행', '을', '가보', '아요']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK-ABlYm9dJo",
        "colab_type": "code",
        "outputId": "037b956c-bd3b-43bd-cb07-107f0fe1d695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "print(kkma.pos(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('ㄴ', 'ETD'), ('당신', 'NP'), (',', 'SP'), ('연휴', 'NNG'), ('에', 'JKM'), ('는', 'JX'), ('여행', 'NNG'), ('을', 'JKO'), ('가보', 'VV'), ('아요', 'EFN')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ofX5acG9ria",
        "colab_type": "code",
        "outputId": "917b2442-6542-4ed2-be13-084c23ee0c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "print(kkma.nouns(\"열심히 코딩한 당신, 연휴에는 여행을 가봐요\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['코딩', '당신', '연휴', '여행']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}